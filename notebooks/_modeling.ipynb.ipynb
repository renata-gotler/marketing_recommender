{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc01b9d5-24db-46dd-a640-60801562076d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements/requirements-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3bec0fc-84e4-4593-9397-9f252a48df1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.transformation.sklearn_preprocessing import PreProcessing\n",
    "from src.model.sklearn_model import Classifier\n",
    "from src.tracker.mlflow_tracker import MLFlowTracker\n",
    "import os\n",
    "import mlflow\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from pyspark.sql.functions import col\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a5b84b-adac-411c-ab77-8eedd167eff5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40a1231-449f-45b1-a469-278ef85d89a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "    dataset = spark.read.json(\"/Volumes/workspace/ifood_case/marketing_recommender/data/processed/sv_customer_offer_relationship.json\")\n",
    "else:\n",
    "    dataset = spark.read.json(\"../data/processed/sv_customer_offer_relationship.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bffd6ed3-5680-478f-bb2b-a9d266c26054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = [\"gender\"]\n",
    "numerical_features = [\n",
    "    \"total_customer_buy\",\n",
    "    \"total_customer_interactions\",\n",
    "    \"age\",\n",
    "    \"credit_card_limit\",\n",
    "    \"customer_total_spent\",\n",
    "    \"avg_customer_spent\",\n",
    "    \"registered_year\"\n",
    "]\n",
    "target = \"best_offer_id\"\n",
    "\n",
    "model_dataset = dataset.select([\"customer_id\"] + categorical_features + numerical_features + [target]).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ccdc88b-c6ed-4271-b4e4-53cc9006e937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert dataset.select(\"customer_id\").dropDuplicates().count() == model_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cee11d95-3798-4a22-af75-458672d6a27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(model_dataset.limit(5))\n",
    "display(model_dataset.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4480bee4-69c7-4885-94dd-5e4d7becf8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = \"/Volumes/workspace/ifood_case/marketing_recommender/sparkml_temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41c8c8b9-e2e7-4c55-b151-09b8fb7ea584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Tive que adaptar o pipeline para sklearn ao invés de spark por limitação do cluster serverless gratuito do Databricks, erro: got the error [JVM_ATTRIBUTE_NOT_SUPPORTED] Directly accessing the underlying Spark driver JVM using the attribute 'sparkContext' is not supported on serverless compute. If you require direct access to these fields, consider using a single-user cluster. For more details on compatibility and limitations, check: https://docs.databricks.com/release-notes/serverless.html#limitations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72a54b0b-9d84-45a9-a6df-23be63b7618e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tracker = MLFlowTracker()\n",
    "classifier = Classifier()\n",
    "preprocessing = PreProcessing()\n",
    "\n",
    "with mlflow.start_run(run_name=\"classifier_xgboost\"):\n",
    "    \n",
    "    preprocessing.build_categorical_transformation_pipeline(categorical_features=categorical_features, imputer_mapping={\"gender\": \"NI\"})\n",
    "    preprocessing.build_numerical_transformation_pipeline(numerical_features=numerical_features)\n",
    "    preprocessing.index_target(target_col=\"best_offer_id\")\n",
    "    preprocessing.assemble_pipeline()\n",
    "    print(len(preprocessing.stages))\n",
    "    pipeline = classifier.build_pipeline(stages=preprocessing.stages, model=XGBClassifier)\n",
    "\n",
    "    # train, test = model_dataset.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "    pandas_df = model_dataset.toPandas()\n",
    "    X = pandas_df.drop(columns=[\"customer_id\", target])\n",
    "    y = pandas_df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    max_depth_choices = [5, 10, 15]\n",
    "    num_trees_choices = [50, 100, 150]\n",
    "\n",
    "    # paramGrid = (\n",
    "    #     ParamGridBuilder()\n",
    "    #     .addGrid(pipeline.getStages()[-1].max_depth, max_depth_choices)\n",
    "    #     .addGrid(pipeline.getStages()[-1].n_estimators, num_trees_choices)\n",
    "    #     .build()\n",
    "    # )\n",
    "\n",
    "    paramGrid = {\n",
    "        \"clf__max_depth\": max_depth_choices,\n",
    "        \"clf__n_estimators\": num_trees_choices,\n",
    "    }\n",
    "    \n",
    "    mlflow.log_param(\"param_grid_size\", len(paramGrid))\n",
    "    mlflow.log_param(\"max_depth_values\", max_depth_choices)\n",
    "    mlflow.log_param(\"num_trees_values\", num_trees_choices)\n",
    "\n",
    "    evaluator = make_scorer(f1_score, average=\"macro\")\n",
    "    # evaluator = MulticlassClassificationEvaluator(\n",
    "    #     labelCol=\"label\",\n",
    "    #     predictionCol=\"prediction\",\n",
    "    #     metricName=metric_name\n",
    "    # )\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "\n",
    "    cv_model = classifier.cross_validation_tuning(X_train, y_train_encoded, pipeline, paramGrid, evaluator)\n",
    "\n",
    "    # best_idx = cv_model.avgMetrics.index(\n",
    "    #     max(cv_model.avgMetrics)\n",
    "    # )\n",
    "    # best_params = cv_model.getEstimatorParamMaps()[best_idx]\n",
    "    best_params= cv_model.best_params_\n",
    "    mlflow.log_metric(\"best_f1_macro_cv\", cv_model.best_score_)\n",
    "    print(best_params)\n",
    "    mlflow.log_params(best_params)\n",
    "    best_pipeline = classifier.build_pipeline(stages=preprocessing.stages, model=XGBClassifier, **best_params)\n",
    "    classifier.train(X_train, y_train_encoded, best_pipeline)\n",
    "    predictions = classifier.model.predict(X_test)\n",
    "    test_results = classifier.evaluate(y_test_encoded, predictions)\n",
    "    cm = classifier.get_confusion_matrix(y_test_encoded, predictions)\n",
    "    normalized_cm = classifier.get_confusion_matrix(y_test_encoded, predictions, normalize=\"true\")\n",
    "    mlflow.log_metrics(test_results)\n",
    "    mlflow.log_params(best_params)\n",
    "    # mlflow.spark.log_model(\n",
    "    #     classifier.model,\n",
    "    #     \"model\",\n",
    "    #     registered_model_name=\"offer-predictions\"\n",
    "    # )\n",
    "    mlflow.sklearn.log_model(\n",
    "        classifier.model,\n",
    "        \"model\",\n",
    "        registered_model_name=\"offer-predictions\",\n",
    "        input_example=X_train.head()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fb791b1-fc0a-4fc6-b134-882bc6fa0a14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "97% acerto em “sem oferta”, baixo acerto em ofertas. Ainda tem que melhorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48ce450-a380-4fae-852f-1a7e00caf8fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb27557b-89c6-445a-a670-071b08cec976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51e7124-fbd4-4688-8d41-83ca6b16fe4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=normalized_cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d3ebf43-fe3c-4cd4-a807-a7f53d1701de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "_modeling.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
